{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vKV7Lb__EJV",
        "outputId": "4f6d8844-d9da-4f78-dfd3-b62bdbf54d98"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp /content/drive/MyDrive/archive_stores/*.* /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfF9kCzkFN4y",
        "outputId": "5181b1ca-8761-4399-97fd-1fb4d6804cb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/actors (2).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/actors.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/CBO2002 - Ocupacao.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/cids_counts.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/Cópia de df_unico4.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/counts_ocupacoes (1).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/counts_ocupacoes (2).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/counts_ocupacoes.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crime_all.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crime_war_2000.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_escola (1).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_escola.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_idade (1).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_idade.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_sexo_2 (1).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_sexo_2 (2).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_sexo_2.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/crosstab_diag_sexo.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/df_modelagem_com_nulos.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/df_modelagem - nulos imputados - dia 20.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/df_unico3_1.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/df_unico4 (1).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/df_unico4 (2).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/df_unico4 (3).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/df_unico4.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/feature_importance.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/GMM_result.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/ocupacoes_sem_nulos.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/tab_cat_diag.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/tab_conting.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/tabela_contingencia (1).gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/tabela_contingencia.gsheet' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/archive_stores/tab_sexo_regiao.gsheet' for reading: Operation not supported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SQLContext\n",
        "from pyspark.sql.functions import lit, expr\n",
        "from pyspark.sql.functions import count\n",
        "from pyspark.sql.functions import col\n",
        "import pyspark.sql.functions as F\n",
        "import random"
      ],
      "metadata": {
        "id": "gOy-v32tMaSN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nxy3W_CL-3J5"
      },
      "outputs": [],
      "source": [
        "# Criando uma SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName('Exercicio Intro') \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Nesta etapa, adicione código para ler o arquivo nomes_aleatorios.txt através do comando spark.read.csv. Carregue-o para dentro de um dataframe chamado df_nomes e, por fim, liste algumas linhas através do método show. Exemplo: df_nomes.show(5)"
      ],
      "metadata": {
        "id": "MXeJBC34c02G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes = spark.read.csv('/content/drive/MyDrive/análise de dados/nomes_aleatorios.txt')\n",
        "df_nomes.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3j4jw_J_lEv",
        "outputId": "d760b7c1-f327-48ba-9a64-1bbded8d011c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|             _c0|\n",
            "+----------------+\n",
            "|  Frances Bennet|\n",
            "|   Jamie Russell|\n",
            "|  Edward Kistler|\n",
            "|   Sheila Maurer|\n",
            "|Donald Golightly|\n",
            "+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Como não informamos no momento da leitura do arquivo, o Spark não identificou o Schema por padrão e definiu todas as colunas como string. Para ver o Schema, use o método df_nomes.printSchema(). Nesta etapa, será necessário adicionar código para renomear a coluna para Nomes, imprimir o esquema e mostrar 10 linhas do dataframe."
      ],
      "metadata": {
        "id": "gzi6NC86dRnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes.printSchema()"
      ],
      "metadata": {
        "id": "wPSUuIcxEice",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08ae35b-88a3-4860-9728-066d4f7e52d8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
        "df_nomes.printSchema()"
      ],
      "metadata": {
        "id": "o2JYrOzbElHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f04284e-92ac-4f1d-b197-adafc95ab369"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Nomes: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes.show(5)"
      ],
      "metadata": {
        "id": "9BW87hqjEoEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd83aeb-79aa-4fb4-9330-292f8ad04cad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|           Nomes|\n",
            "+----------------+\n",
            "|  Frances Bennet|\n",
            "|   Jamie Russell|\n",
            "|  Edward Kistler|\n",
            "|   Sheila Maurer|\n",
            "|Donald Golightly|\n",
            "+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_coluna_randomizada(nome_coluna,lista,dataframe):\n",
        "  return dataframe.withColumn(\n",
        "      nome_coluna,\n",
        "      F.array(\n",
        "          [F.lit(x) for x in lista]\n",
        "      ).getItem(\n",
        "          (F.rand()*len(lista)).cast(\"int\")\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "obZaDNjIIiSP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ao dataframe (df_nomes), adicione nova coluna chamada Escolaridade e atribua para cada linha um dos três valores de forma aleatória: Fundamental, Medio ou Superior."
      ],
      "metadata": {
        "id": "KZoUPcQddanE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "escolaridade = ['Fundamental','Medio','Superior']\n",
        "\n",
        "df_nomes = add_coluna_randomizada(\"Escolaridade\",escolaridade,df_nomes)"
      ],
      "metadata": {
        "id": "zLcto5kUHBDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4640910e-1e23-4e41-ebdb-84d74b3be3f1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/column.py:458: FutureWarning: A column as 'key' in getItem is deprecated as of Spark 3.0, and will not be supported in the future release. Use `column[key]` or `column.key` syntax instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes.show(10)"
      ],
      "metadata": {
        "id": "pK-tC1sh1fB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440f7bc6-69c6-4038-98e7-fdf22fe6115a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+\n",
            "|            Nomes|Escolaridade|\n",
            "+-----------------+------------+\n",
            "|   Frances Bennet|       Medio|\n",
            "|    Jamie Russell|    Superior|\n",
            "|   Edward Kistler|    Superior|\n",
            "|    Sheila Maurer|       Medio|\n",
            "| Donald Golightly|    Superior|\n",
            "|       David Gray|    Superior|\n",
            "|      Joy Bennett|    Superior|\n",
            "|      Paul Kriese|    Superior|\n",
            "|Berniece Ornellas| Fundamental|\n",
            "|    Brian Farrell|       Medio|\n",
            "+-----------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ao dataframe (df_nomes), adicione nova coluna chamada Pais e atribua para cada linha o nome de um dos 13 países da América do Sul, de forma aleatória."
      ],
      "metadata": {
        "id": "oK2vvZQXdwek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paises = [\"Peru\",\"Bolivia\",\"Argentina\",\"Brasil\",\"Chile\",\"Colômbia\",\"Equador\",\n",
        "          \"Guiana\",\"Paraguai\",\"Suriname\",\"Uruguai\",\"Venezuela\"]\n",
        "\n",
        "df_nomes = add_coluna_randomizada(\"Pais\",paises,df_nomes)"
      ],
      "metadata": {
        "id": "4ANByi8VFCP9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes.show(5)"
      ],
      "metadata": {
        "id": "402z24Gv2wsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fc24e1-b2d9-4368-b65a-72c36dc6aa83"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------+---------+\n",
            "|           Nomes|Escolaridade|     Pais|\n",
            "+----------------+------------+---------+\n",
            "|  Frances Bennet|       Medio|  Equador|\n",
            "|   Jamie Russell|    Superior| Colômbia|\n",
            "|  Edward Kistler|    Superior|  Uruguai|\n",
            "|   Sheila Maurer|       Medio|Venezuela|\n",
            "|Donald Golightly|    Superior|    Chile|\n",
            "+----------------+------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ao dataframe (df_nomes), adicione nova coluna chamada AnoNascimento e atribua para cada linha um valor de ano entre 1945 e 2010, de forma aleatória."
      ],
      "metadata": {
        "id": "H6PoZlRbd82M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anos = range(1945,2010)\n",
        "\n",
        "df_nomes = add_coluna_randomizada(\"AnoNascimento\",anos,df_nomes)"
      ],
      "metadata": {
        "id": "BkgF6M2YKD77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes.show(5)"
      ],
      "metadata": {
        "id": "O71nLw494EYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b472b0c0-738f-4f7d-8425-c82bd5c0b9cd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------+---------+-------------+\n",
            "|           Nomes|Escolaridade|     Pais|AnoNascimento|\n",
            "+----------------+------------+---------+-------------+\n",
            "|  Frances Bennet|       Medio|  Equador|         1989|\n",
            "|   Jamie Russell|    Superior| Colômbia|         1983|\n",
            "|  Edward Kistler|    Superior|  Uruguai|         1976|\n",
            "|   Sheila Maurer|       Medio|Venezuela|         1983|\n",
            "|Donald Golightly|    Superior|    Chile|         1965|\n",
            "+----------------+------------+---------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando o método select do dataframe (df_nomes), selecione as pessoas que nasceram neste século. Armazene o resultado em outro dataframe chamado df_select e mostre 10 nomes deste."
      ],
      "metadata": {
        "id": "QhfukJS7eIqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo a coluna \"AnoNascimento\" para tipo inteiro\n",
        "df_nomes = df_nomes.withColumn(\"AnoNascimento\", df_nomes[\"AnoNascimento\"])\n",
        "\n",
        "# Filtrando os registros de pessoas que nasceram neste século e armazenando o resultado em um novo dataframe\n",
        "df_select = df_nomes.select(\"Nomes\",\"AnoNascimento\")\n",
        "df_select = df_select.filter(df_select.AnoNascimento >= 2000)\n",
        "\n",
        "df_select.show(10)"
      ],
      "metadata": {
        "id": "xvgz2gH7MyLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26672ba4-5a6d-45d1-cbd4-d84214613aa9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+\n",
            "|         Nomes|AnoNascimento|\n",
            "+--------------+-------------+\n",
            "|   Frank Wiley|         2009|\n",
            "| Ricky Gilbert|         2009|\n",
            "| Michael Agnew|         2005|\n",
            "|  James Barton|         2008|\n",
            "| Jenna Johnson|         2002|\n",
            "|  Jerry Remick|         2005|\n",
            "|  Curtis Sutch|         2004|\n",
            "|   Shelia Ceja|         2008|\n",
            "|  Jason Martin|         2008|\n",
            "|David Rathbone|         2004|\n",
            "+--------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando Spark SQL repita o processo da Pergunta 6."
      ],
      "metadata": {
        "id": "VsNvB99deWE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma tabela temporária chamada 'pessoas' para execução das consultas com Spark SQL\n",
        "df_nomes.createOrReplaceTempView('pessoas')"
      ],
      "metadata": {
        "id": "7UPz46hSY_zt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando consulta SQL para selecionas as pessoas que nasceram neste século\n",
        "nascimento_filtrado_sql = spark.sql('SELECT * FROM pessoas WHERE AnoNascimento >= 2000')\n",
        "\n",
        "nascimento_filtrado_sql.show(10)"
      ],
      "metadata": {
        "id": "IU-T7jVoUqzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41d33ef-24d2-4e7d-970f-e818e90bb981"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+---------+-------------+\n",
            "|         Nomes|Escolaridade|     Pais|AnoNascimento|\n",
            "+--------------+------------+---------+-------------+\n",
            "|   Frank Wiley| Fundamental|Argentina|         2009|\n",
            "| Ricky Gilbert| Fundamental| Suriname|         2009|\n",
            "| Michael Agnew| Fundamental| Suriname|         2005|\n",
            "|  James Barton|    Superior|    Chile|         2008|\n",
            "| Jenna Johnson|       Medio|  Equador|         2002|\n",
            "|  Jerry Remick| Fundamental|Argentina|         2005|\n",
            "|  Curtis Sutch| Fundamental|   Guiana|         2004|\n",
            "|   Shelia Ceja|    Superior|  Bolivia|         2008|\n",
            "|  Jason Martin| Fundamental|Argentina|         2008|\n",
            "|David Rathbone|       Medio|    Chile|         2004|\n",
            "+--------------+------------+---------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando o método select do Dataframe df_nomes, Conte o número de pessoas que são da geração Millennials (nascidos entre 1980 e 1994) no Dataset"
      ],
      "metadata": {
        "id": "5b7FzHEHed00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando as pessoas que nasceram entre 1980 e 1994\n",
        "df_millennials = df_nomes.filter((col('AnoNascimento') >= 1980) & (col('AnoNascimento') <= 1994))\n",
        "\n",
        "# Contando o número de pessoas da geração Millennials\n",
        "count_millennials = df_millennials.count()\n",
        "\n",
        "print(f\"Número de pessoas da geração Millennials: {count_millennials}\")"
      ],
      "metadata": {
        "id": "5psWmzJRWn_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a82e3e0-5635-441d-d0ac-f6fa529a15a2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de pessoas da geração Millennials: 2308848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Repita o processo da Pergunta 8 utilizando Spark SQL"
      ],
      "metadata": {
        "id": "YM0xlGAQejqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando consulta SQL para contar o número de pessoas da geração Millennials\n",
        "resultado_sql = spark.sql(\"SELECT COUNT(*) AS count_millennials FROM pessoas WHERE AnoNascimento BETWEEN 1980 AND 1994\")\n",
        "\n",
        "# Extraindo o resultado da consulta SQL\n",
        "count_millennials_sql = resultado_sql.first()[\"count_millennials\"]\n",
        "\n",
        "print(f\"Número de pessoas da geração Millennials: {count_millennials}\")"
      ],
      "metadata": {
        "id": "3JvfE2yLYEUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5446ed1-28b6-4f6c-e115-14ef956ba26c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de pessoas da geração Millennials: 2308848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma função para gerar a consulta SQL de contagem por geração\n",
        "def consulta_geracao(geracao,ano_inicial,ano_final):\n",
        "  query = f\"\"\"\n",
        "      SELECT Pais, '{geracao}' AS Geracao, COUNT(*) AS Quantidade\n",
        "      FROM pessoas\n",
        "      WHERE AnoNascimento BETWEEN {ano_inicial} AND {ano_final}\n",
        "      GROUP BY Pais\n",
        "  \"\"\"\n",
        "  return query\n",
        "\n",
        "# Informações de cada geração\n",
        "geracoes = [\n",
        "    {\"nome\": \"Baby Boomers\", \"ano_inicio\": 1944, \"ano_fim\": 1964},\n",
        "    {\"nome\": \"Geração X\", \"ano_inicio\": 1965, \"ano_fim\": 1979},\n",
        "    {\"nome\": \"Millennials\", \"ano_inicio\": 1980, \"ano_fim\": 1994},\n",
        "    {\"nome\": \"Geração Z\", \"ano_inicio\": 1995, \"ano_fim\": 2015}\n",
        "]\n",
        "\n",
        "# Consultando os resultados para cada geração e armazenando em uma lista\n",
        "resultados_geracoes = []\n",
        "for geracao_info in geracoes:\n",
        "    geracao_query = consulta_geracao(geracao_info[\"nome\"],geracao_info[\"ano_inicio\"],geracao_info[\"ano_fim\"])\n",
        "    resultado = spark.sql(geracao_query)\n",
        "    resultados_geracoes.append(resultado)\n",
        "\n",
        "# Combinando os DataFrames usando union\n",
        "df_resultado = resultados_geracoes[0]\n",
        "for i in range(1, len(resultados_geracoes)):\n",
        "    df_resultado = df_resultado.union(resultados_geracoes[i])\n",
        "\n",
        "# Ordenando o resultado por Pais, Geração e Quantidade\n",
        "df_resultado = df_resultado.orderBy(\"Pais\", \"Geracao\", \"Quantidade\")\n",
        "\n",
        "df_resultado.show()"
      ],
      "metadata": {
        "id": "Wdu4_1DpYtGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b73c377-9323-4266-855e-9dd1fa615a99"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+----------+\n",
            "|     Pais|     Geracao|Quantidade|\n",
            "+---------+------------+----------+\n",
            "|Argentina|Baby Boomers|    256205|\n",
            "|Argentina|   Geração X|    192019|\n",
            "|Argentina|   Geração Z|    192081|\n",
            "|Argentina| Millennials|    191615|\n",
            "|  Bolivia|Baby Boomers|    256143|\n",
            "|  Bolivia|   Geração X|    192601|\n",
            "|  Bolivia|   Geração Z|    191544|\n",
            "|  Bolivia| Millennials|    192919|\n",
            "|   Brasil|Baby Boomers|    256235|\n",
            "|   Brasil|   Geração X|    191955|\n",
            "|   Brasil|   Geração Z|    192212|\n",
            "|   Brasil| Millennials|    193121|\n",
            "|    Chile|Baby Boomers|    255974|\n",
            "|    Chile|   Geração X|    192704|\n",
            "|    Chile|   Geração Z|    191860|\n",
            "|    Chile| Millennials|    192267|\n",
            "| Colômbia|Baby Boomers|    256296|\n",
            "| Colômbia|   Geração X|    192057|\n",
            "| Colômbia|   Geração Z|    192439|\n",
            "| Colômbia| Millennials|    191913|\n",
            "+---------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}